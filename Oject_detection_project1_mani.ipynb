{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eT3iDrGFRVwE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "sxMZBMS5ReTd",
    "outputId": "16ca8e66-8751-4e1e-a4bd-b462722c2985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.2.0.32)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages (from opencv-python) (1.17.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "ZyCS6OTOyCsL",
    "outputId": "2afcd855-dd5d-4602-ab72-24de4cdba487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageai==2.0.1\n",
      "  Downloading https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.1/imageai-2.0.1-py3-none-any.whl (137kB)\n",
      "Installing collected packages: imageai\n",
      "  Found existing installation: imageai 2.1.5\n",
      "    Uninstalling imageai-2.1.5:\n",
      "      Successfully uninstalled imageai-2.1.5\n",
      "Successfully installed imageai-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.1/imageai-2.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "GkVT_n-1RrYf",
    "outputId": "efd77460-e576-49a6-82f1-b838d4633725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageai\n",
      "  Using cached https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: h5py in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imageai) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imageai) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages (from imageai) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imageai) (6.2.1)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from imageai) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from h5py->imageai) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (2.4.5)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->imageai) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->imageai) (42.0.2.post20191203)\n",
      "Installing collected packages: imageai\n",
      "  Found existing installation: imageai 2.0.1\n",
      "    Uninstalling imageai-2.0.1:\n",
      "      Successfully uninstalled imageai-2.0.1\n",
      "Successfully installed imageai-2.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imageai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "TvR72wOrRzud",
    "outputId": "1a5507b6-e1e6-4c5a-f34f-bfccef17acb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Hp\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "## Importing Object Detection class from imageai.detection\n",
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "d_Igiss2wMCp",
    "outputId": "698b31eb-4909-460a-8dbf-0a71f10e0034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from h5py) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\hp\\appdata\\roaming\\python\\python37\\site-packages (from h5py) (1.17.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "imhz0InNlJmf",
    "outputId": "a87b85db-9673-492c-ff0d-fee90a40e78d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\krish naik\\\\Deep-Learning-Face-Recognition-master'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vhejXMwklPYU",
    "outputId": "708ce101-9fad-4d44-bee7-df8ae12882e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\krish naik\\\\Deep-Learning-Face-Recognition-master'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"D:\\krish naik\\Deep-Learning-Face-Recognition-master\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtVSueLIReDU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uqc5jdv_kuYJ",
    "outputId": "bf89c786-3fe6-422c-bf26-060a42247a7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\krish naik\\\\Deep-Learning-Face-Recognition-master'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_path ='D:\\krish naik\\Deep-Learning-Face-Recognition-master'\n",
    "execution_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msFGGkoblISe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\krish naik\\\\Deep-Learning-Face-Recognition-master'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image_path=\"D:\\krish naik\\Deep-Learning-Face-Recognition-master\"\n",
    "output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7sS8iJWfjXL6",
    "outputId": "9800651a-8b17-4463-b155-2cd206b3c1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking <tf.Variable 'Variable_30:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_31:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_32:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_33:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_34:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Ensure you specified correct input image, input type, output type and/or output image path ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageai\\Detection\\__init__.py\u001b[0m in \u001b[0;36mdetectObjectsFromImage\u001b[1;34m(self, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image_bgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;32melif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"array\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageai\\Detection\\keras_retinanet\\utils\\image.py\u001b[0m in \u001b[0;36mread_image_bgr\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_image_bgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2765\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2766\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2767\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\krish naik\\\\Deep-Learning-Face-Recognition-master\\\\bengaluru-traffic-trauma-44000-intersections-only-5000-cops.jpeg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ad422426cfde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetModelPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_image_path\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"resnet50_coco_best_v2.0.1.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectObjectsFromImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecution_path\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"bengaluru-traffic-trauma-44000-intersections-only-5000-cops.jpeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_image_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_image_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"image_new.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meachObject\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdetections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m    \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meachObject\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" : \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meachObject\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"percentage_probability\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageai\\Detection\\__init__.py\u001b[0m in \u001b[0;36mdetectObjectsFromImage\u001b[1;34m(self, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 544\u001b[1;33m                     \"Ensure you specified correct input image, input type, output type and/or output image path \")\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m     def CustomObjects(self, person=False, bicycle=False, car=False, motorcycle=False, airplane=False,\n",
      "\u001b[1;31mValueError\u001b[0m: Ensure you specified correct input image, input type, output type and/or output image path "
     ]
    }
   ],
   "source": [
    "## Defining objectDetection class to detector\n",
    "## Set the model to RetinaNet\n",
    "## Loading the model into ObjectDetection class\n",
    "## Detection function and parsed in the input image path and the output image path\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath(os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.setModelPath(os.path.join(output_image_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"bengaluru-traffic-trauma-44000-intersections-only-5000-cops.jpeg\"), output_image_path=os.path.join(output_image_path, \"image_new.jpg\"))\n",
    "for eachObject in detections:\n",
    "   print(eachObject[\"name\"] + \" : \" + eachObject[\"percentage_probability\"] )\n",
    "   print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "colab_type": "code",
    "id": "dafhQNpR00vM",
    "outputId": "023f5b7e-cc55-4f8e-84e7-517c34745a95"
   },
   "outputs": [],
   "source": [
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"image2.jpeg\"), output_image_path=os.path.join(execution_path , \"image_new2.jpg\"))\n",
    "for eachObject in detections:\n",
    "   print(eachObject[\"name\"] + \" : \" + eachObject[\"percentage_probability\"] )\n",
    "   print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "id": "WyMhCuaMvBZB",
    "outputId": "1ea8a100-3451-4fdb-cd0c-2ac54c5f01d8"
   },
   "outputs": [],
   "source": [
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"unnamed (4).png\"), output_image_path=os.path.join(execution_path , \"image_new3.jpg\"))\n",
    "for eachObject in detections:\n",
    "   print(eachObject[\"name\"] + \" : \" + eachObject[\"percentage_probability\"] )\n",
    "   print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "colab_type": "code",
    "id": "VxklntmVRfuU",
    "outputId": "a421e5b7-4477-4dd5-da92-82c53f3ebf8f"
   },
   "outputs": [],
   "source": [
    "pip install py-agender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRBb5ibDet87"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLmnCZvwSa0Y"
   },
   "outputs": [],
   "source": [
    "from pyagender import PyAgender\n",
    "\n",
    "agender = PyAgender() \n",
    "# see available options in __init__() src\n",
    "\n",
    "faces = agender.detect_genders_ages(cv2.imread('image_new3.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jXPsJpyefMRQ",
    "outputId": "1e29e278-534b-4ff2-c802-b2adcf7d10a8"
   },
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_64wOJIczGQL",
    "outputId": "f9add381-61c7-463d-cbea-6cefce77d4a1"
   },
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCJfGIMZzwQR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2ViGjJ850aVc",
    "outputId": "f14e2804-e3b4-4f38-9802-da5f93baf984"
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "EFjlpVmS1itq",
    "outputId": "6e8ad81b-2556-47cc-9852-c9f3258ab23b"
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLnb0xHH1Ndw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMz6jlpJz0kr"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('image2.jpeg')\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "B0XZeiNC4CTI",
    "outputId": "c05c423c-7665-4897-ee4b-48dd90f3f70f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "Ziof-Pwh3-h7",
    "outputId": "6369d2a7-1c69-411b-deea-f8cd0512daf3"
   },
   "outputs": [],
   "source": [
    "# Convert the image into gray scale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img_gray, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "wiC9tJis2Seg",
    "outputId": "d57fd47e-73e9-40b6-b272-96643f709bdc"
   },
   "outputs": [],
   "source": [
    "# Convert the image into RGB\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "QEPAc2zh4qEx",
    "outputId": "b6f14e4c-78bb-4a4d-a778-4d9c35e7ec23"
   },
   "outputs": [],
   "source": [
    "# Plot the three channels of the image\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 3, figsize = (20, 20))\n",
    "for i in range(0, 3):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(img_rgb[:, :, i], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "id": "Y879pCRf8TOC",
    "outputId": "976e3fb3-f8e1-40a1-87d8-f24cd7cb737d"
   },
   "outputs": [],
   "source": [
    "# Transform the image into HSV and HLS models\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "img_hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "# Plot the converted images\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (20, 20))\n",
    "ax1.imshow(img_hsv)\n",
    "ax2.imshow(img_hls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lN2JBdGzkeMx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Oject_detection_project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
